{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfMFDAJkxjLx",
        "outputId": "16386018-2411-4b3d-a3cf-242df3121e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Music Recommendation Model...\n",
            "Epoch 20: Train Loss: 1.4543, Test Loss: 2.4177\n",
            "Epoch 40: Train Loss: 0.8179, Test Loss: 2.8023\n",
            "Epoch 60: Train Loss: 0.5438, Test Loss: 3.0330\n",
            "Epoch 80: Train Loss: 0.4268, Test Loss: 3.1503\n",
            "Epoch 100: Train Loss: 0.3576, Test Loss: 3.0704\n",
            "Epoch 120: Train Loss: 0.3179, Test Loss: 3.1039\n",
            "Epoch 140: Train Loss: 0.2897, Test Loss: 3.1401\n",
            "Epoch 160: Train Loss: 0.2644, Test Loss: 3.0921\n",
            "Epoch 180: Train Loss: 0.2484, Test Loss: 3.0493\n",
            "Epoch 200: Train Loss: 0.2323, Test Loss: 3.1142\n",
            "\n",
            "Recommended songs for user 0: [ 235  117 2960 4466 1954]\n",
            "\n",
            "Final Test Loss: 3.1142\n"
          ]
        }
      ],
      "source": [
        "# Music Recommendation System using Neural Collaborative Filtering in PyTorch\n",
        "# -----------------------------------------------------------------------------\n",
        "# This script builds a music recommendation system using synthetic user-song rating data.\n",
        "# It trains a neural network to predict ratings a user would give to a song.\n",
        "# Based on this, the model can recommend songs with the highest predicted ratings.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Set seed for reproducibility and choose device (GPU if available)\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generate synthetic user-song interaction data\n",
        "num_users = 1000\n",
        "num_songs = 5000\n",
        "np.random.seed(42)\n",
        "ratings_data = {\n",
        "    'user_id': [],\n",
        "    'song_id': [],\n",
        "    'rating': []\n",
        "}\n",
        "# Create 50,000 random user-song ratings between 1 and 5\n",
        "for _ in range(50000):\n",
        "    user_id = np.random.randint(0, num_users)\n",
        "    song_id = np.random.randint(0, num_songs)\n",
        "    rating = np.random.randint(1, 6)\n",
        "    ratings_data['user_id'].append(user_id)\n",
        "    ratings_data['song_id'].append(song_id)\n",
        "    ratings_data['rating'].append(rating)\n",
        "ratings_df = pd.DataFrame(ratings_data)\n",
        "\n",
        "# Custom Dataset class to handle our ratings data\n",
        "class MusicDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.users = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
        "        self.songs = torch.tensor(df['song_id'].values, dtype=torch.long)\n",
        "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.songs[idx], self.ratings[idx]\n",
        "\n",
        "# Split our data into 80% training and 20% testing\n",
        "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
        "train_dataset = MusicDataset(train_df)\n",
        "test_dataset = MusicDataset(test_df)\n",
        "\n",
        "# Load data in batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Define a simple Neural Collaborative Filtering model\n",
        "class MusicRecommender(nn.Module):\n",
        "    def __init__(self, num_users, num_songs, embedding_dim=50):\n",
        "        super(MusicRecommender, self).__init__()\n",
        "        # Embedding layers convert user/song IDs to dense vectors\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
        "        self.song_embedding = nn.Embedding(num_songs, embedding_dim)\n",
        "\n",
        "        # Fully connected layers to learn complex interactions between user and song features\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(embedding_dim * 2, 128),  # Combine both embeddings and pass through FC layer\n",
        "            nn.ReLU(),                         # Activation to introduce non-linearity\n",
        "            nn.Dropout(0.3),                   # Dropout to prevent overfitting\n",
        "            nn.Linear(128, 64),                # Another FC layer for deeper learning\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1)                   # Final output: predicted rating (a single float)\n",
        "        )\n",
        "\n",
        "    def forward(self, user, song):\n",
        "        # Look up user and song embeddings\n",
        "        user_emb = self.user_embedding(user)\n",
        "        song_emb = self.song_embedding(song)\n",
        "        # Concatenate user and song features to form the input to the FC layers\n",
        "        x = torch.cat([user_emb, song_emb], dim=-1)\n",
        "        return self.fc_layers(x).squeeze()  # Output a scalar rating prediction\n",
        "\n",
        "# Initialize the model, loss function and optimizer\n",
        "model = MusicRecommender(num_users, num_songs).to(device)\n",
        "criterion = nn.MSELoss()  # Mean Squared Error to measure prediction quality\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Function to train our model\n",
        "def train_model(model, train_loader, test_loader, epochs=200):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        running_loss = 0.0\n",
        "        for users, songs, ratings in train_loader:\n",
        "            # Move data to GPU if available\n",
        "            users, songs, ratings = users.to(device), songs.to(device), ratings.to(device)\n",
        "\n",
        "            optimizer.zero_grad()        # Reset gradients\n",
        "            outputs = model(users, songs)  # Forward pass\n",
        "            loss = criterion(outputs, ratings)  # Compute loss\n",
        "            loss.backward()              # Backpropagation\n",
        "            optimizer.step()             # Update model weights\n",
        "            running_loss += loss.item()  # Accumulate loss\n",
        "\n",
        "        # Evaluate on test data every 20 epochs\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            model.eval()  # Switch to evaluation mode\n",
        "            test_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for users, songs, ratings in test_loader:\n",
        "                    users, songs, ratings = users.to(device), songs.to(device), ratings.to(device)\n",
        "                    outputs = model(users, songs)\n",
        "                    loss = criterion(outputs, ratings)\n",
        "                    test_loss += loss.item()\n",
        "            print(f\"Epoch {epoch + 1}: \"\n",
        "                  f\"Train Loss: {running_loss/len(train_loader):.4f}, \"\n",
        "                  f\"Test Loss: {test_loss/len(test_loader):.4f}\")\n",
        "\n",
        "# Start training the model\n",
        "print(\"Training Music Recommendation Model...\")\n",
        "train_model(model, train_loader, test_loader)\n",
        "\n",
        "# Recommend top N songs for a given user\n",
        "def recommend_songs(model, user_id, num_songs, num_recommend=5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Generate a list of all song IDs\n",
        "        song_ids = torch.arange(num_songs, dtype=torch.long, device=device)\n",
        "        # Create a tensor of the same user ID to match song IDs\n",
        "        user_ids = torch.full_like(song_ids, user_id)\n",
        "        # Predict ratings for all songs\n",
        "        predictions = model(user_ids, song_ids)\n",
        "        # Get top N song indices with highest predicted ratings\n",
        "        _, top_indices = torch.topk(predictions, num_recommend)\n",
        "        return top_indices.cpu().numpy()\n",
        "\n",
        "# Example usage: Recommend 5 songs for user 0\n",
        "recommended_songs = recommend_songs(model, user_id=0, num_songs=num_songs)\n",
        "print(f\"\\nRecommended songs for user 0: {recommended_songs}\")\n",
        "\n",
        "# Final evaluation on test set\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for users, songs, ratings in test_loader:\n",
        "        users, songs, ratings = users.to(device), songs.to(device), ratings.to(device)\n",
        "        outputs = model(users, songs)\n",
        "        loss = criterion(outputs, ratings)\n",
        "        test_loss += loss.item()\n",
        "print(f\"\\nFinal Test Loss: {test_loss/len(test_loader):.4f}\")\n"
      ]
    }
  ]
}